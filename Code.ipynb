{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import csv\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    line = text\n",
    "    #conversion to lowercae letters\n",
    "    line = line.lower()\n",
    "    #removing all http hyperlink\n",
    "    line = re.sub('(\\s)http\\S+','',line)\n",
    "    #removing punctuation masrks\n",
    "    punctuations = '''!()-![]{};:+'\"\\,<>./?@#$%^&*_~'''\n",
    "    line = ''.join([i for i in line if not i in punctuations])\n",
    "    \n",
    "    line = re.sub(r\"\\d\", \"\", line)\n",
    "    return(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_pos = ('./Dataset/train/pos')\n",
    "Train_neg = ('./Dataset/train/neg')\n",
    "Test_pos = ('./Dataset/test/pos')\n",
    "Test_neg = ('./Dataset/test/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Dataset/stop_words.txt', 'r') as f:\n",
    "    stop_wordslist = [line.strip() for line in f]\n",
    "    punctuation = '''!'\\\"#$&'()*+,-./:;<=>?@[\\]^_`{|}~.'''\n",
    "\n",
    "def stop_words(single_tweet):\n",
    "    single_tweet= single_tweet.split()\n",
    "    # check word from tweet with stop_wordlist given above\n",
    "    without_SW = [x for x in single_tweet if x not in stop_wordslist]\n",
    "    #get all those words which are not in stop_wordslist\n",
    "    #print unique_lst\n",
    "    unique_wordlst = ' '.join(without_SW)   \n",
    "    return unique_wordlst \n",
    "\n",
    "def data_clean(text):\n",
    "    text = data_cleaning(text)\n",
    "    line = stop_words(text)\n",
    "    return line\n",
    "def extract_features(Folder, label):\n",
    "    data_list = list()\n",
    "    labels = list()\n",
    "        \n",
    "    for text_file in listdir(Folder):\n",
    "         #get text from file\n",
    "        File = open(Folder+\"/\"+text_file, 'r', encoding='utf-8', errors='ignore')\n",
    "        # read the text\n",
    "        text = File.read()\n",
    "        line = []\n",
    "        #clean data\n",
    "        text = data_clean(text)\n",
    "                \n",
    "        File.close()\n",
    "        #add label\n",
    "        labels.append(label)\n",
    "        #add cleaned text\n",
    "        data_list.append(text)\n",
    "      \n",
    "    return data_list, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_positive, train_pos_labels = extract_features(Train_pos, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''''df = pd.DataFrame(Train_positive)\n",
    "#print(df)\n",
    "#'''''df[0] = df[0].apply(lambda x: x.split('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_negative, train_neg_labels = extract_features(Train_neg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_positive, test_pos_labels = extract_features(Test_pos, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_negative, test_neg_labels = extract_features(Test_neg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "#combine positive and negative text features for training and testing data\n",
    "for i in (Train_positive):\n",
    "    X_train.append(i)\n",
    "    Y_train.append(1)\n",
    "for i in (Train_negative):\n",
    "    X_train.append(i)\n",
    "    Y_train.append(0)\n",
    "#print(np.array(X_train))\n",
    "#print(X_train)\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in (Test_positive):\n",
    "    X_test.append(i)\n",
    "    Y_test.append(1)\n",
    "for i in (Test_negative):\n",
    "    X_test.append(i)\n",
    "    Y_test.append(0)\n",
    "#print(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_x = vectorizer.fit_transform((np.array(X_train)))\n",
    "test_x = vectorizer.transform((np.array(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB()\n",
    "NB.fit(train_x, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = NB.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.82432\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score: ',accuracy_score(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[10992  2884]\n",
      " [ 1508  9616]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(Y_pred, Y_test)\n",
    "print('Confusion matrix:',)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
